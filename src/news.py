import feedparser
from typing import List, Dict, Optional
from datetime import datetime, timedelta
from urllib.parse import quote_plus
import json
import time
import re
import requests
from bs4 import BeautifulSoup
from pathlib import Path
import pytz
from src.utils.log_manager import LogManager, LogCategory

class News:
    """ì½”ì¸ ê´€ë ¨ ë‰´ìŠ¤ ìˆ˜ì§‘ê¸°"""
    
    # ë‰´ìŠ¤ ì†ŒìŠ¤ URL
    GOOGLE_NEWS_RSS = "https://news.google.com/rss/search?q={query}&hl=ko&gl=KR&ceid=KR:ko"
    NAVER_NEWS_SEARCH = "https://search.naver.com/search.naver?where=news&query={query}"
    COINDESK_RSS = "https://www.coindesk.com/arc/outboundfeeds/rss/?outputType=xml"  # ê¸°ë³¸ RSS
    COINDESK_SEARCH = "https://www.coindesk.com/search?q={query}"  # ê²€ìƒ‰ìš©
    COINTELEGRAPH_RSS = "https://cointelegraph.com/rss"  # ê¸°ë³¸ RSS
    COINTELEGRAPH_SEARCH = "https://cointelegraph.com/search?query={query}"  # ê²€ìƒ‰ìš©
    
    # ì‹¬ë³¼ë³„ ì¶”ê°€ ê²€ìƒ‰ í‚¤ì›Œë“œ
    SYMBOL_KEYWORDS = {
        "BTC": ["ë¹„íŠ¸ì½”ì¸", "Bitcoin", "BTC", "$BTC", "bitcoin"],
        "ETH": ["ì´ë”ë¦¬ì›€", "Ethereum", "ETH", "$ETH", "ethereum"],
        "XRP": ["ë¦¬í”Œ", "Ripple", "XRP", "$XRP", "ripple"],
        "DOGE": ["ë„ì§€ì½”ì¸", "Dogecoin", "DOGE", "$DOGE", "dogecoin"],
        "SOL": ["ì†”ë¼ë‚˜", "Solana", "SOL", "$SOL", "solana"],
    }
    
    # ê¸°ë³¸ ê²€ìƒ‰ í‚¤ì›Œë“œ (ëª¨ë“  ì‹¬ë³¼ì— ê³µí†µ ì ìš©)
    COMMON_KEYWORDS = [
        "ê°€ìƒìì‚°", "ì•”í˜¸í™”í", "í¬ë¦½í† ",
        "SEC", "CFTC", "ì½”ì¸ë² ì´ìŠ¤", "ë°”ì´ë‚¸ìŠ¤",
        "cryptocurrency", "crypto", "blockchain"
    ]
    
    def __init__(self, log_manager: Optional[LogManager] = None):
        """ì´ˆê¸°í™”
        
        Args:
            log_manager: ë¡œê·¸ ë§¤ë‹ˆì € (ì„ íƒì‚¬í•­)
        """
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
        self.last_update = None
        self.cached_news = {}  # symbolë³„ ìºì‹œ
        self.cache_duration = 300  # 5ë¶„ ìºì‹œ
        self.log_manager = log_manager
        
        # ì‹¤í–‰ ì‹œê°„ ê¸°ë°˜ ë””ë ‰í† ë¦¬ ìƒì„±
        base_dir = Path(".temp")
        base_dir.mkdir(exist_ok=True)
        
        now = datetime.now()
        run_id = now.strftime("%Y%m%d_%H%M%S")
        self.run_dir = base_dir / run_id
        self.run_dir.mkdir(exist_ok=True)
        
        if self.log_manager:
            self.log_manager.log(
                category=LogCategory.SYSTEM,
                message="ë‰´ìŠ¤ ìˆ˜ì§‘ê¸° ì´ˆê¸°í™” ì™„ë£Œ",
                data={"run_dir": str(self.run_dir)}
            )
    
    def _convert_datetime(self, data: Dict) -> Dict:
        """datetime ê°ì²´ë¥¼ ISO í˜•ì‹ ë¬¸ìì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
        if isinstance(data, dict):
            return {k: self._convert_datetime(v) for k, v in data.items()}
        elif isinstance(data, list):
            return [self._convert_datetime(item) for item in data]
        elif isinstance(data, datetime):
            return data.isoformat()
        return data
    
    def _parse_datetime(self, date_str: str) -> datetime:
        """ë‰´ìŠ¤ ë°œí–‰ì¼ìë¥¼ íŒŒì‹±í•©ë‹ˆë‹¤."""
        try:
            # RSS í‘œì¤€ í˜•ì‹
            return datetime.strptime(date_str, "%a, %d %b %Y %H:%M:%S %Z")
        except:
            try:
                # ë„¤ì´ë²„ ë‰´ìŠ¤ í˜•ì‹
                if "ë¶„ ì „" in date_str:
                    minutes = int(date_str.replace("ë¶„ ì „", ""))
                    return datetime.now() - timedelta(minutes=minutes)
                elif "ì‹œê°„ ì „" in date_str:
                    hours = int(date_str.replace("ì‹œê°„ ì „", ""))
                    return datetime.now() - timedelta(hours=hours)
                elif "ì¼ ì „" in date_str:
                    days = int(date_str.replace("ì¼ ì „", ""))
                    return datetime.now() - timedelta(days=days)
                elif re.match(r'\d{4}\.\d{2}\.\d{2}\.', date_str):
                    # YYYY.MM.DD. í˜•ì‹
                    return datetime.strptime(date_str.strip('.'), "%Y.%m.%d")
                elif re.match(r'\d{4}\-\d{2}\-\d{2}', date_str):
                    # YYYY-MM-DD í˜•ì‹
                    return datetime.strptime(date_str.split()[0], "%Y-%m-%d")
                elif re.match(r'[A-Za-z]{3}, \d{2} [A-Za-z]{3} \d{4} \d{2}:\d{2}:\d{2} \+\d{4}', date_str):
                    # ì‹œê°„ëŒ€ê°€ í¬í•¨ëœ RSS í˜•ì‹ì„ KSTë¡œ ë³€í™˜
                    utc_time = datetime.strptime(date_str, "%a, %d %b %Y %H:%M:%S %z")
                    kst = pytz.timezone('Asia/Seoul')
                    return utc_time.astimezone(kst).replace(tzinfo=None)
                else:
                    if self.log_manager:
                        self.log_manager.log(
                            category=LogCategory.ERROR,
                            message="ì§€ì›í•˜ì§€ ì•ŠëŠ” ë‚ ì§œ í˜•ì‹",
                            data={"date_str": date_str}
                        )
                    return datetime.now()
            except Exception as e:
                if self.log_manager:
                    self.log_manager.log(
                        category=LogCategory.ERROR,
                        message="ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨",
                        data={"date_str": date_str, "error": str(e)}
                    )
                return datetime.now()
    
    def _clean_text(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ë¥¼ ì •ì œí•©ë‹ˆë‹¤."""
        # HTML íƒœê·¸ ë° ì—”í‹°í‹° ì œê±°
        text = re.sub(r'<[^>]+>', '', text)
        text = re.sub(r'&[a-zA-Z]+;', ' ', text)
        # íŠ¹ìˆ˜ë¬¸ì ì •ì œ (í•œê¸€, ì˜ë¬¸, ìˆ«ì, ê¸°ë³¸ ë¬¸ì¥ë¶€í˜¸ë§Œ í—ˆìš©)
        text = re.sub(r'[^\w\sê°€-í£.,Â·\-()%]', '', text)
        # ì—°ì†ëœ ê³µë°± ì œê±°
        text = re.sub(r'\s+', ' ', text)
        return text.strip()
    
    def _get_symbol_keywords(self, symbol: str) -> List[str]:
        """ì‹¬ë³¼ì— ëŒ€í•œ ê²€ìƒ‰ í‚¤ì›Œë“œ ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        symbol = symbol.upper()
        keywords = self.SYMBOL_KEYWORDS.get(symbol, [symbol])
        if symbol not in self.SYMBOL_KEYWORDS:
            # ê¸°ë³¸ í‚¤ì›Œë“œ ìƒì„±
            keywords.extend([
                f"{symbol} ì½”ì¸",
                f"{symbol} ì‹œì„¸",
                f"{symbol} ê°€ê²©"
            ])
        return keywords
    
    def _get_coindesk_news(self, keyword: str, max_age_hours: int = 24) -> List[Dict]:
        """CoinDesk ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤."""
        news_items = []
        now = datetime.now()
        
        try:
            if self.log_manager:
                self.log_manager.log(
                    category=LogCategory.SYSTEM,
                    message="CoinDesk ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘",
                    data={"keyword": keyword, "max_age_hours": max_age_hours}
                )
            
            # RSS í”¼ë“œì—ì„œ ìµœì‹  ë‰´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
            feed = feedparser.parse(self.COINDESK_RSS)
            
            for entry in feed.entries:
                # í‚¤ì›Œë“œ í•„í„°ë§
                if not any(kw.lower() in entry.title.lower() or 
                          kw.lower() in entry.description.lower() 
                          for kw in [keyword]):
                    continue
                
                published_at = self._parse_datetime(entry.published)
                age_hours = (now - published_at).total_seconds() / 3600
                
                if age_hours > max_age_hours:
                    continue
                
                # ì œëª©ê³¼ ì¶œì²˜ ì •ì œ
                clean_title = self._clean_text(entry.title)
                
                # ìš”ì•½ ì •ì œ
                summary = self._clean_text(entry.description)
                if clean_title in summary:
                    summary = summary.replace(clean_title, "").strip()
                
                news_items.append({
                    "title": clean_title,
                    "summary": summary,
                    "published_at": published_at,
                    "source": "CoinDesk"
                })
            
            # ê²€ìƒ‰ APIë¥¼ í†µí•œ ì¶”ê°€ ë‰´ìŠ¤ ìˆ˜ì§‘
            search_url = self.COINDESK_SEARCH.format(query=quote_plus(keyword))
            response = self.session.get(search_url)
            soup = BeautifulSoup(response.text, 'html.parser')
            
            for article in soup.select('article'):
                title_elem = article.select_one('h6')
                if not title_elem:
                    continue
                
                title = self._clean_text(title_elem.text)
                
                time_elem = article.select_one('time')
                published = time_elem.get('datetime') if time_elem else None
                published_at = self._parse_datetime(published) if published else now
                
                age_hours = (now - published_at).total_seconds() / 3600
                if age_hours > max_age_hours:
                    continue
                
                summary = ""
                desc_elem = article.select_one('p')
                if desc_elem:
                    summary = self._clean_text(desc_elem.text)
                
                news_items.append({
                    "title": title,
                    "summary": summary,
                    "published_at": published_at,
                    "source": "CoinDesk"
                })
            
            if self.log_manager:
                self.log_manager.log(
                    category=LogCategory.SYSTEM,
                    message="CoinDesk ë‰´ìŠ¤ ìˆ˜ì§‘ ì™„ë£Œ",
                    data={"keyword": keyword, "news_count": len(news_items)}
                )
            
        except Exception as e:
            if self.log_manager:
                self.log_manager.log(
                    category=LogCategory.ERROR,
                    message="CoinDesk ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨",
                    data={"keyword": keyword, "error": str(e)}
                )
        
        return news_items

    def _collect_cointelegraph_news(self, keyword: str, max_age_hours: int) -> List[Dict]:
        """Cointelegraph ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤."""
        news_items = []
        now = datetime.now()
        
        try:
            if self.log_manager:
                self.log_manager.log(
                    category=LogCategory.SYSTEM,
                    message="Cointelegraph ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘",
                    data={"keyword": keyword, "max_age_hours": max_age_hours}
                )
            
            # RSS í”¼ë“œì—ì„œ ìµœì‹  ë‰´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
            feed = feedparser.parse(self.COINTELEGRAPH_RSS)
            
            for entry in feed.entries:
                # í‚¤ì›Œë“œ í•„í„°ë§
                if not any(kw.lower() in entry.title.lower() or 
                          kw.lower() in entry.description.lower() 
                          for kw in [keyword]):
                    continue
                
                published_at = self._parse_datetime(entry.published)
                age_hours = (now - published_at).total_seconds() / 3600
                
                if age_hours > max_age_hours:
                    continue
                
                # ì œëª©ê³¼ ì¶œì²˜ ì •ì œ
                clean_title = self._clean_text(entry.title)
                
                # ìš”ì•½ ì •ì œ
                summary = self._clean_text(entry.description)
                if clean_title in summary:
                    summary = summary.replace(clean_title, "").strip()
                
                news_items.append({
                    "title": clean_title,
                    "summary": summary,
                    "published_at": published_at,
                    "source": "Cointelegraph"
                })
            
            # ê²€ìƒ‰ APIë¥¼ í†µí•œ ì¶”ê°€ ë‰´ìŠ¤ ìˆ˜ì§‘
            search_url = self.COINTELEGRAPH_SEARCH.format(query=quote_plus(keyword))
            response = self.session.get(search_url)
            soup = BeautifulSoup(response.text, 'html.parser')
            
            for article in soup.select('article.post-card'):
                title_elem = article.select_one('.post-card__title')
                if not title_elem:
                    continue
                
                title = self._clean_text(title_elem.text)
                
                time_elem = article.select_one('time')
                published = time_elem.get('datetime') if time_elem else None
                published_at = self._parse_datetime(published) if published else now
                
                age_hours = (now - published_at).total_seconds() / 3600
                if age_hours > max_age_hours:
                    continue
                
                summary = ""
                desc_elem = article.select_one('.post-card__text')
                if desc_elem:
                    summary = self._clean_text(desc_elem.text)
                
                news_items.append({
                    "title": title,
                    "summary": summary,
                    "published_at": published_at,
                    "source": "Cointelegraph"
                })
            
            if self.log_manager:
                self.log_manager.log(
                    category=LogCategory.SYSTEM,
                    message="Cointelegraph ë‰´ìŠ¤ ìˆ˜ì§‘ ì™„ë£Œ",
                    data={"keyword": keyword, "news_count": len(news_items)}
                )
            
        except Exception as e:
            if self.log_manager:
                self.log_manager.log(
                    category=LogCategory.ERROR,
                    message="Cointelegraph ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨",
                    data={"keyword": keyword, "error": str(e)}
                )
        
        return news_items

    def get_news(
        self,
        symbol: str,
        max_age_hours: int = 24,
        limit: int = 10,
        use_cache: bool = False
    ) -> List[Dict]:
        """íŠ¹ì • ì‹¬ë³¼ì˜ ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
        
        Args:
            symbol: ì‹¬ë³¼ (ì˜ˆ: BTC)
            max_age_hours: ìµœëŒ€ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œê°„ (ì‹œê°„)
            limit: ìˆ˜ì§‘í•  ë‰´ìŠ¤ ê°œìˆ˜
            use_cache: ìºì‹œ ì‚¬ìš© ì—¬ë¶€
            
        Returns:
            List[Dict]: ìˆ˜ì§‘ëœ ë‰´ìŠ¤ ëª©ë¡
        """
        symbol = symbol.upper()
        
        all_news = []
        keywords = self._get_symbol_keywords(symbol)
        
        # í‚¤ì›Œë“œë³„ ë‰´ìŠ¤ ìˆ˜ì§‘
        for keyword in keywords:
            try:
                # êµ¬ê¸€ ë‰´ìŠ¤ ìˆ˜ì§‘
                google_news = self._collect_google_news(keyword, max_age_hours)
                all_news.extend(google_news)
                
                # ë„¤ì´ë²„ ë‰´ìŠ¤ ìˆ˜ì§‘
                naver_news = self._collect_naver_news(keyword, max_age_hours)
                all_news.extend(naver_news)
                
                # CoinDesk ë‰´ìŠ¤ ìˆ˜ì§‘
                coindesk_news = self._get_coindesk_news(keyword, max_age_hours)
                all_news.extend(coindesk_news)
                
                # Cointelegraph ë‰´ìŠ¤ ìˆ˜ì§‘
                cointelegraph_news = self._collect_cointelegraph_news(keyword, max_age_hours)
                all_news.extend(cointelegraph_news)
                
                time.sleep(1)  # API í˜¸ì¶œ ê°„ê²© ì¡°ì ˆ
                
            except Exception as e:
                if self.log_manager:
                    self.log_manager.log(
                        category=LogCategory.ERROR,
                        message=f"{symbol} {keyword} ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨",
                        data={"error": str(e)}
                    )
                continue
                
        # ì¤‘ë³µ ì œê±° (ì œëª© ê¸°ì¤€)
        unique_news = list({news["title"]: news for news in all_news}.values())
        
        # ë°œí–‰ì¼ì‹œ ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬ í›„ limit ì ìš©
        unique_news.sort(key=lambda x: x["published_at"], reverse=True)
        news_list = unique_news[:limit]
        
        if self.log_manager:
            self.log_manager.log(
                category=LogCategory.SYSTEM,
                message=f"{symbol} ë‰´ìŠ¤ ìˆ˜ì§‘ ì™„ë£Œ",
                data={
                    "news_count": len(news_list),
                    "sources": list(set(news["source"] for news in news_list))
                }
            )
        
        return news_list
    
    def format_news(
        self,
        news_items: List[Dict],
        show_summary: bool = True
    ) -> str:
        """ë‰´ìŠ¤ ê²°ê³¼ë¥¼ ë³´ê¸° ì¢‹ê²Œ í¬ë§·íŒ…í•©ë‹ˆë‹¤."""
        if not news_items:
            return "ìˆ˜ì§‘ëœ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        current_time = datetime.now().strftime("%Y-%m-%d %H:%M")
        
        output = []
        output.append(f"\nğŸ“° ë‰´ìŠ¤ ëª¨ë‹ˆí„°ë§ ({current_time})")
        output.append("=" * 60)
        
        # í†µê³„ ì •ë³´
        sources = {}
        for item in news_items:
            sources[item['source']] = sources.get(item['source'], 0) + 1
        
        output.append(f"\nğŸ“Š ë‰´ìŠ¤ í†µê³„")
        output.append(f"â€¢ ì´ ë‰´ìŠ¤: {len(news_items)}ê°œ")
        output.append(f"â€¢ ì–¸ë¡ ì‚¬ë³„ ë‰´ìŠ¤:")
        for src, count in sorted(sources.items(), key=lambda x: x[1], reverse=True):
            output.append(f"  - {src}: {count}ê°œ")
        
        # ë‰´ìŠ¤ ëª©ë¡
        output.append("\nğŸ“‘ ë‰´ìŠ¤ ëª©ë¡")
        for i, item in enumerate(news_items, 1):
            published = item["published_at"].strftime("%Y-%m-%d %H:%M")
            output.append(f"\n{i}. {item['title']}")
            output.append(f"   {item['source']} | {published}")
            
            if show_summary and item["summary"]:
                summary = item["summary"]
                if len(summary) > 200:
                    summary = summary[:197] + "..."
                output.append(f"\n   {summary}")
        
        return "\n".join(output)

    def _collect_google_news(self, keyword: str, max_age_hours: int) -> List[Dict]:
        """êµ¬ê¸€ ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤."""
        news_items = []
        now = datetime.now()
        
        try:
            if self.log_manager:
                self.log_manager.log(
                    category=LogCategory.SYSTEM,
                    message="êµ¬ê¸€ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘",
                    data={"keyword": keyword, "max_age_hours": max_age_hours}
                )
            
            url = self.GOOGLE_NEWS_RSS.format(query=quote_plus(keyword))
            feed = feedparser.parse(url)
            
            for entry in feed.entries:
                published_at = self._parse_datetime(entry.published)
                age_hours = (now - published_at).total_seconds() / 3600
                
                if age_hours > max_age_hours:
                    continue
                
                # ì œëª©ê³¼ ì¶œì²˜ ë¶„ë¦¬
                title_parts = entry.title.split(' - ')
                clean_title = self._clean_text(title_parts[0])
                source = title_parts[-1] if len(title_parts) > 1 else "Unknown"
                
                # ìš”ì•½ ì •ì œ
                summary = self._clean_text(entry.get("summary", ""))
                if clean_title in summary:
                    summary = summary.replace(clean_title, "").strip()
                
                news_items.append({
                    "title": clean_title,
                    "summary": summary,
                    "published_at": published_at,
                    "source": source
                })
            
            if self.log_manager:
                self.log_manager.log(
                    category=LogCategory.SYSTEM,
                    message="êµ¬ê¸€ ë‰´ìŠ¤ ìˆ˜ì§‘ ì™„ë£Œ",
                    data={"keyword": keyword, "news_count": len(news_items)}
                )
            
        except Exception as e:
            if self.log_manager:
                self.log_manager.log(
                    category=LogCategory.ERROR,
                    message="êµ¬ê¸€ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨",
                    data={"keyword": keyword, "error": str(e)}
                )
        
        return news_items
    
    def _collect_naver_news(self, keyword: str, max_age_hours: int) -> List[Dict]:
        """ë„¤ì´ë²„ ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤."""
        news_items = []
        now = datetime.now()
        
        try:
            if self.log_manager:
                self.log_manager.log(
                    category=LogCategory.SYSTEM,
                    message="ë„¤ì´ë²„ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘",
                    data={"keyword": keyword, "max_age_hours": max_age_hours}
                )
            
            url = self.NAVER_NEWS_SEARCH.format(query=quote_plus(keyword))
            response = self.session.get(url)
            soup = BeautifulSoup(response.text, 'html.parser')
            
            for news in soup.select('.news_area')[:5]:
                title_elem = news.select_one('.news_tit')
                if not title_elem:
                    continue
                
                title = self._clean_text(title_elem.get('title', ''))
                
                desc_elem = news.select_one('.dsc_txt_wrap')
                summary = self._clean_text(desc_elem.text) if desc_elem else ""
                
                source_elem = news.select_one('.info_group a:first-child')
                source = source_elem.text.strip() if source_elem else "Unknown"
                
                time_elem = news.select_one('.info_group span.info')
                published = time_elem.text.strip() if time_elem else ""
                published_at = self._parse_datetime(published)
                
                age_hours = (now - published_at).total_seconds() / 3600
                if age_hours > max_age_hours:
                    continue
                
                news_items.append({
                    "title": title,
                    "summary": summary,
                    "published_at": published_at,
                    "source": source
                })
            
            if self.log_manager:
                self.log_manager.log(
                    category=LogCategory.SYSTEM,
                    message="ë„¤ì´ë²„ ë‰´ìŠ¤ ìˆ˜ì§‘ ì™„ë£Œ",
                    data={"keyword": keyword, "news_count": len(news_items)}
                )
                
        except Exception as e:
            if self.log_manager:
                self.log_manager.log(
                    category=LogCategory.ERROR,
                    message="ë„¤ì´ë²„ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨",
                    data={"keyword": keyword, "error": str(e)}
                )
        
        return news_items 